{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMghkmD2GmXs1seiu4LxAsu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP0I9mf5f5_h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_csv('sample_data/student-mat.csv', sep= ';')\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "JFVYV9gvf7ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remover as instâncias com valores faltantes do DataFrame\n",
        "dados = dados.dropna()\n",
        "print(dados)"
      ],
      "metadata": {
        "id": "su0AEO1uga6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remover instâncias duplicadas\n",
        "dados = dados.drop_duplicates()\n",
        "print(dados)"
      ],
      "metadata": {
        "id": "lo6PVyCcgfhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dados[['sex', 'age', 'Pstatus', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']]"
      ],
      "metadata": {
        "id": "fzqtN9VYhZLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(10)"
      ],
      "metadata": {
        "id": "xQrc7dBGhnmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicando One_Hot Encoding para as variaveis categoricas\n",
        "X = pd.get_dummies(X, columns=['sex','Pstatus','schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic'])\n",
        "X.head()"
      ],
      "metadata": {
        "id": "cy9Linhfhphs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando um novo dataframe com a média das duas colunas\n",
        "df_media = pd.DataFrame({'media': (dados['G1'] + dados['G2'] + dados['G3'])/3})\n",
        "df_media.head()"
      ],
      "metadata": {
        "id": "hcd-n-VUjqQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando um dataframe com uma coluna binária \"Aprovado\"\n",
        "Y = pd.DataFrame({'Aprovado': [1 if media >= 12 else 0 for media in df_media['media']]})\n",
        "Y.head()"
      ],
      "metadata": {
        "id": "9EHrsQEEj6Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "aad9wHAEkBL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# definindo quais colunas serão normalizadas\n",
        "colunas_a_normalizar = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
        "\n",
        "#fazendo os ajustes dos dados\n",
        "scaler.fit(X_train[colunas_a_normalizar])\n"
      ],
      "metadata": {
        "id": "8DU9xojVkDVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizando as colunas selecionadas dos dados de treinamento e substituindo os dados originais no DataFrame\n",
        "X_train[colunas_a_normalizar] = scaler.transform(X_train[colunas_a_normalizar])\n",
        "\n",
        "# imprimindo o DataFrame resultante\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "llWCojAvlWZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizando as colunas selecionadas dos dados de teste e substituindo os dados originais no DataFrame\n",
        "X_test[colunas_a_normalizar] = scaler.transform(X_test[colunas_a_normalizar])\n",
        "\n",
        "# imprimindo o DataFrame resultante\n",
        "X_test.head()"
      ],
      "metadata": {
        "id": "-F9SusDClZk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo = LogisticRegression()\n",
        "\n",
        "#treinando o modelo\n",
        "modelo.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "WxjGuVFIldpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fazendo predições com os dados de teste\n",
        "y_pred = modelo.predict(X_test)\n"
      ],
      "metadata": {
        "id": "TW9JGn1KmV4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "#quantos aprovados e reprovados foram preditos corretamente\n",
        "print(\"Acurácia: {:.2f}\".format(accuracy))\n",
        "\n",
        "#do nro total de preditos como aprovados, quantos são mesmo aprovados\n",
        "print(\"Precisão: {:.2f}\".format(precision))\n",
        "\n",
        "#do nro total de aprovados na base de dados quantos foram preditos como aprovados\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "\n",
        "#média harmônica entre precisão e recall\n",
        "print(\"F1: {:.2f}\".format(f1))"
      ],
      "metadata": {
        "id": "i9nkfAV6mYMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}